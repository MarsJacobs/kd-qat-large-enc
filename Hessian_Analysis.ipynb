{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f36a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pprint\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\" # Set GPU Index to use\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import copy\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from tqdm import tqdm\n",
    "from transformer import BertForSequenceClassification,WEIGHTS_NAME, CONFIG_NAME\n",
    "from transformer.modeling_quant import BertForSequenceClassification as QuantBertForSequenceClassification\n",
    "from transformer import BertTokenizer\n",
    "from transformer import BertAdam\n",
    "from transformer import BertConfig\n",
    "from transformer import QuantizeLinear, QuantizeAct, BertSelfAttention, FP_BertSelfAttention, ClipLinear\n",
    "from utils_glue import *\n",
    "from bertviz import model_view\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn.functional as F\n",
    "        \n",
    "def get_tensor_data(output_mode, features):\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "\n",
    "    all_seq_lengths = torch.tensor([f.seq_length for f in features], dtype=torch.long)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    tensor_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,all_label_ids, all_seq_lengths)\n",
    "    return tensor_data, all_label_ids\n",
    "\n",
    "def do_eval(model, task_name, eval_dataloader,\n",
    "            device, output_mode, eval_labels, num_labels, teacher_model=None):\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "\n",
    "    for batch_ in tqdm(eval_dataloader, desc=\"Inference\"):\n",
    "        batch_ = tuple(t.to(device) for t in batch_)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
    "\n",
    "            # teacher attnmap test\n",
    "            if teacher_model is not None: \n",
    "                teacher_logits, teacher_atts, teacher_reps, teacher_probs, teacher_values = teacher_model(input_ids, segment_ids, input_mask)\n",
    "                logits, loss, cls_loss, rep_loss, output_loss, attmap_loss, attscore_loss, coeff_list, _  = model(input_ids, segment_ids, input_mask, teacher_outputs=(teacher_probs, teacher_values, teacher_reps, teacher_logits, teacher_atts), output_mode=output_mode, seq_lengths=seq_lengths)\n",
    "            else:\n",
    "                logits, _, _, _, _, _, _, _, _ = model(input_ids, segment_ids, input_mask)\n",
    "        # create eval loss and other metric required by the task\n",
    "        if output_mode == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif output_mode == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(\n",
    "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "    preds = preds[0]\n",
    "    if output_mode == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif output_mode == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result = compute_metrics(task_name, preds, eval_labels.numpy())\n",
    "    result['eval_loss'] = eval_loss\n",
    "    return result\n",
    "\n",
    "def soft_cross_entropy(predicts, targets):\n",
    "    student_likelihood = torch.nn.functional.log_softmax(predicts, dim=-1)\n",
    "    targets_prob = torch.nn.functional.softmax(targets, dim=-1)\n",
    "    return torch.sum((- targets_prob * student_likelihood), dim=-1).mean()\n",
    "\n",
    "processors = {\n",
    "    \"cola\": ColaProcessor,\n",
    "    \"mnli\": MnliProcessor,\n",
    "    \"mnli-mm\": MnliMismatchedProcessor,\n",
    "    \"mrpc\": MrpcProcessor,\n",
    "    \"sst-2\": Sst2Processor,\n",
    "    \"sts-b\": StsbProcessor,\n",
    "    \"qqp\": QqpProcessor,\n",
    "    \"qnli\": QnliProcessor,\n",
    "    \"rte\": RteProcessor   \n",
    "}\n",
    "\n",
    "output_modes = {\n",
    "        \"cola\": \"classification\",\n",
    "        \"mnli\": \"classification\",\n",
    "        \"mrpc\": \"classification\",\n",
    "        \"sst-2\": \"classification\",\n",
    "        \"sts-b\": \"regression\",\n",
    "        \"qqp\": \"classification\",\n",
    "        \"qnli\": \"classification\",\n",
    "        \"rte\": \"classification\"\n",
    "}\n",
    "\n",
    "default_params = {\n",
    "        \"cola\": {\"max_seq_length\": 64,\"batch_size\":16,\"eval_step\":200}, #50\n",
    "        \"mnli\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":1000},\n",
    "        \"mrpc\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":200},\n",
    "        \"sst-2\": {\"max_seq_length\": 64,\"batch_size\":32,\"eval_step\":200}, #64\n",
    "        \"sts-b\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":50},\n",
    "        \"qqp\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":1000},\n",
    "        \"qnli\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":1000},\n",
    "        \"rte\": {\"max_seq_length\": 128,\"batch_size\":16,\"eval_step\":5000} # 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a5fbf",
   "metadata": {},
   "source": [
    "## GLUE Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bf0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"cola\"\n",
    "bert_size = \"large\"\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    layer_num = 24\n",
    "    head_num = 16\n",
    "else: \n",
    "    layer_num = 12\n",
    "    head_num = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6d38e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d89bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/17 03:27:06 AM Writing example 0 of 8551\n",
      "05/17 03:27:06 AM *** Example ***\n",
      "05/17 03:27:06 AM guid: train-0\n",
      "05/17 03:27:06 AM tokens: [CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]\n",
      "05/17 03:27:06 AM input_ids: 101 2256 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/17 03:27:06 AM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/17 03:27:06 AM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/17 03:27:06 AM label: 1\n",
      "05/17 03:27:06 AM label_id: 1\n",
      "Num examples = 8551\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_dir = \"models\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    model_dir = os.path.join(model_dir, \"BERT_large\")\n",
    "    output_dir = os.path.join(output_dir, \"BERT_large\")\n",
    "\n",
    "teacher_model_dir = os.path.join(model_dir,task_name)\n",
    "\n",
    "# Processor & Task Info\n",
    "processor = processors[task_name]()\n",
    "output_mode = output_modes[task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "\n",
    "if task_name in default_params:\n",
    "    batch_size = default_params[task_name][\"batch_size\"]\n",
    "    max_seq_length = default_params[task_name][\"max_seq_length\"]\n",
    "    eval_step = default_params[task_name][\"eval_step\"]\n",
    "    \n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(teacher_model_dir, do_lower_case=True)\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "data_dir = os.path.join(\"data\",task_name)\n",
    "processed_data_dir = os.path.join(data_dir,'preprocessed')\n",
    "\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "\n",
    "train_features = convert_examples_to_features(train_examples, label_list,\n",
    "                                max_seq_length, tokenizer, output_mode)\n",
    "\n",
    "train_features = train_features[:int(len(train_features))]\n",
    "print(f\"Num examples = {len(train_features)}\")\n",
    "\n",
    "train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
    "train_sampler = SequentialSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# eval_examples = processor.get_dev_examples(data_dir)\n",
    "# eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
    "# # dev_file = train_file = os.path.join(processed_data_dir,'dev.pkl') \n",
    "# # eval_features = pickle.load(open(dev_file,'rb'))\n",
    "\n",
    "# eval_data, eval_labels = get_tensor_data(\"classification\", eval_features)\n",
    "# eval_sampler = SequentialSampler(eval_data)\n",
    "# eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=1)\n",
    "# eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
    "\n",
    "# eval_examples = processor.get_dev_examples(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404f01a",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba53d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/17 03:27:32 AM loading configuration file output/BERT_large/cola/exploration/1SB_map_O/config.json\n",
      "05/17 03:27:38 AM Loading model models/BERT_large/cola/pytorch_model.bin\n",
      "05/17 03:27:39 AM loading model...\n",
      "05/17 03:27:39 AM done!\n",
      "05/17 03:27:39 AM Weights from pretrained model not used in BertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "05/17 03:27:46 AM Loading model output/BERT_large/cola/exploration/sarq_step1_ci_O/pytorch_model.bin\n",
      "05/17 03:27:47 AM loading model...\n",
      "05/17 03:27:47 AM done!\n",
      "05/17 03:27:47 AM Weights from pretrained model not used in BertForSequenceClassification: ['coeff']\n",
      "\n",
      "==> Load Model DONE\n",
      "==> Test Inference\n"
     ]
    }
   ],
   "source": [
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "mse_func = MSELoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_dir = \"models\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    model_dir = os.path.join(model_dir, \"BERT_large\")\n",
    "    output_dir = os.path.join(output_dir, \"BERT_large\")\n",
    "\n",
    "student_model_dir = os.path.join(model_dir,task_name)\n",
    "teacher_model_dir = os.path.join(model_dir,task_name)\n",
    "# # Teacher Model Build\n",
    "\n",
    "# teacher_model = BertForSequenceClassification.from_pretrained(teacher_model_dir, num_labels=num_labels)\n",
    "# teacher_model.to(device)\n",
    "# teacher_model.eval()\n",
    "\n",
    "# Student Model Build - Normal Init\n",
    "quant_model_name = \"1SB_map_O\"\n",
    "sarq_model_name = \"sarq_step1_ci_O\"\n",
    "\n",
    "quant_model_dir = os.path.join(output_dir, task_name, \"exploration\", quant_model_name)  \n",
    "sarq_model_dir = os.path.join(output_dir, task_name, \"exploration\", sarq_model_name)  \n",
    "normal_init_dir = os.path.join(model_dir,task_name)\n",
    "\n",
    "quant_config = BertConfig.from_pretrained(quant_model_dir)             \n",
    "\n",
    "normal_model = QuantBertForSequenceClassification.from_pretrained(normal_init_dir, config = quant_config, num_labels=num_labels)\n",
    "normal_model.to(device)\n",
    "sarq_model = QuantBertForSequenceClassification.from_pretrained(sarq_model_dir, config = quant_config, num_labels=num_labels)\n",
    "\n",
    "normal_model.to(device)\n",
    "sarq_model.to(device)\n",
    "\n",
    "normal_model.eval()\n",
    "sarq_model.eval()\n",
    "\n",
    "print()\n",
    "print(\"==> Load Model DONE\")\n",
    "print(\"==> Test Inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f487fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_mode == \"classification\":\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "\n",
    "elif output_mode == \"regression\":\n",
    "    loss_fct = MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78607664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|â–‹                                                                                                                                                                                                                                                                                                                                                                               | 1/535 [03:21<29:57:28, 201.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3408402/365738161.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhessian_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtop_eigenvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_eigenvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtc_max_eigens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc_max_eigens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtop_eigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/SARQ_BERT/hessian.py\u001b[0m in \u001b[0;36meigenvalues\u001b[0;34m(self, maxIter, tol, top_n)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morthnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/SARQ_BERT/utils.py\u001b[0m in \u001b[0;36morthnormal\u001b[0;34m(w, v_list)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/SARQ_BERT/utils.py\u001b[0m in \u001b[0;36mgroup_add\u001b[0;34m(params, update, alpha)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hessian import hessian\n",
    "from tqdm import tqdm\n",
    "\n",
    "tc_max_eigens = []\n",
    "for batch in tqdm(train_dataloader):\n",
    "    input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
    "    hessian_comp = hessian(normal_model, data=(input_ids, label_ids), criterion=loss_fct, cuda=True, input_zip = (input_ids, segment_ids, input_mask))\n",
    "    top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues(top_n=5)\n",
    "    tc_max_eigens = tc_max_eigens + top_eigenvalues\n",
    "\n",
    "print(\"==> Teacher Model Eigen Value DONE!\")\n",
    "# st_max_eigens = []\n",
    "# for batch in tqdm(train_dataloader):\n",
    "#     input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
    "#     hessian_comp = hessian(student_model, data=(input_ids, label_ids), criterion=loss_fct, cuda=True)\n",
    "#     top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues(top_n=5)\n",
    "#     st_max_eigens = st_max_eigens + top_eigenvalues\n",
    "# print(\"==> Student Model Eigen Value DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f40e36",
   "metadata": {},
   "source": [
    "## Plot KDE Max Eigenvalues density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "658cb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_eigens = []\n",
    "neg_eigens = []\n",
    "for eigen in tc_max_eigens:\n",
    "    if eigen > 0:\n",
    "        pos_eigens.append(eigen)\n",
    "    else:\n",
    "        neg_eigens.append(eigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0bf8fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(pos_eigens)\n",
    "sns.kdeplot(neg_eigens)\n",
    "# tc_max_eigens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9df746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
